# -*- coding: utf-8 -*-
"""CNN_task3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1EPm8ruNPJZ4Ty8yfH9fp_jgTNpOlhddh
"""

import kagglehub

# Download latest version
path = kagglehub.dataset_download("l33tc0d3r/indian-food-classification")

print("Path to dataset files:", path)

import os
os.listdir('/kaggle/input/indian-food-classification/Food Classification')

import os
from PIL import Image

data_dir='/kaggle/input/indian-food-classification/Food Classification'
valid_ext=['jpeg','jpg','bmp','png','webp']

for image_class in os.listdir(data_dir):
    class_path = os.path.join(data_dir, image_class)
    if not os.path.isdir(class_path):
        continue

    for image in os.listdir(class_path):
        image_path = os.path.join(class_path, image)

        try:
            # ---- First open: read metadata ----
            with Image.open(image_path) as img:
                img_format = img.format.lower()

            if img_format not in valid_ext:
                print(f"Invalid format: {image_path}, Detected format: {img_format}")
                continue   # don't delete yet

            # ---- Second open: verify integrity ----
            with Image.open(image_path) as img:
                img.verify()

        except Exception as e:
            print(f"Corrupted image: {image_path}, Error: {e}")

import tensorflow as tf
from tensorflow import keras

data = tf.keras.utils.image_dataset_from_directory(data_dir,seed=42,image_size=(224, 224))

data_iterator = data.as_numpy_iterator()
batch = data_iterator.next()

import matplotlib.pyplot as plt
fig, ax = plt.subplots(ncols=4, figsize=(20,20))
for idx, img in enumerate(batch[0][:4]):
    ax[idx].imshow(img.astype(int))
    ax[idx].title.set_text(batch[1][idx])

# data = data.map(lambda x,y: (x/255, y))

data_iter = data.as_numpy_iterator().next()

# import matplotlib.pyplot as plt
# fig, ax = plt.subplots(ncols=4, figsize=(20,20))
# for idx, img in enumerate(data_iter[0][:4]):
#     ax[idx].imshow(img)
#     ax[idx].title.set_text(data_iter[1][idx])

data = data.shuffle(buffer_size=6269, seed=42)

train_size = int(len(data)*.7)
val_size = int(len(data)*.1)

train_size

val_size

train_ds = data.take(train_size)
val_ds   = data.skip(train_size).take(val_size)
test_ds  = data.skip(train_size + val_size)

# train_iter=train_ds.as_numpy_iterator().next()

# train_iter[0].shape

train_ds

data_augmentation = tf.keras.Sequential([
    tf.keras.layers.RandomFlip("horizontal"),
    tf.keras.layers.RandomRotation(0.1),
    tf.keras.layers.RandomZoom(0.1),
])

base_model = tf.keras.applications.MobileNetV2(
    input_shape=(224, 224, 3),
    include_top=False,
    weights="imagenet"
)

base_model.trainable = False   # Phase 1

inputs = tf.keras.Input(shape=(224, 224, 3))
x = data_augmentation(inputs)
x = tf.keras.applications.mobilenet_v2.preprocess_input(x)

x = base_model(x, training=False)
x = tf.keras.layers.GlobalAveragePooling2D()(x)

x = tf.keras.layers.Dense(256, activation="relu")(x)
x = tf.keras.layers.Dropout(0.5)(x)

outputs = tf.keras.layers.Dense(20, activation="softmax")(x)

model = tf.keras.Model(inputs, outputs)

model.compile(
    optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),
    loss="sparse_categorical_crossentropy",
    metrics=["accuracy"]
)

history = model.fit(
    train_ds,
    validation_data=val_ds,
    epochs=10
)

base_model.trainable = True

# Freeze bottom layers, fine-tune top ones
for layer in base_model.layers[:-30]:
    layer.trainable = False

model.compile(
    optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),
    loss="sparse_categorical_crossentropy",
    metrics=["accuracy"]
)

history_fine = model.fit(
    train_ds,
    validation_data=val_ds,
    epochs=10
)

test_loss, test_acc = model.evaluate(test_ds)
print("Test Accuracy:", test_acc)

plt.plot(history_fine.history['accuracy'])
plt.plot(history_fine.history['val_accuracy'])
plt.legend(['train','test'],loc='upper left')
plt.show()

plt.plot(history_fine.history['loss'])
plt.plot(history_fine.history['val_loss'])
plt.legend(['train','test'],loc='upper left')
plt.show()

plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.legend(['train','test'],loc='upper left')
plt.show()

plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.legend(['train','test'],loc='upper left')
plt.show()

model.save("indian_food_classifer.h5")

model.save("indian_food_classifier.keras")